{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_w, img_h = 28, 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fake_input_batch = np.random.uniform(low=0, high=255, size=(32, 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_block(input_tensor: tf.Tensor, in_filters: int, out_filters: int, stride=1) -> tf.Tensor:\n",
    "    # FIXME - may want to apply batch-norm here\n",
    "    t = tf.nn.relu(input_tensor)\n",
    "    \n",
    "    # Downsample for the skip connection\n",
    "    # FIXME - should this start close to an identity transformation?\n",
    "    kernel_ds = tf.Variable(tf.truncated_normal(shape=(1, 1, in_filters, out_filters), dtype=tf.float32, stddev=1e-4))\n",
    "    t_downsampled = tf.nn.conv2d(t, kernel_ds, strides=(1, stride, stride, 1), padding='SAME')\n",
    "    \n",
    "    kernel_c1 = tf.Variable(tf.truncated_normal(shape=(3, 3, in_filters, out_filters), dtype=tf.float32, stddev=1e-4))\n",
    "    t = tf.nn.conv2d(t, kernel_c1, strides=(1, stride, stride, 1), padding='SAME')\n",
    "    # FIXME - should also apply batch norm here to match Chen et al.\n",
    "    t = tf.nn.relu(t)\n",
    "    \n",
    "    kernel_c2 = tf.Variable(tf.truncated_normal(shape=(3, 3, out_filters, out_filters), dtype=tf.float32, stddev=1e-4))\n",
    "    t = tf.nn.conv2d(t, kernel_c2, strides=(1, 1, 1, 1), padding='SAME')\n",
    "    \n",
    "    # Skip connection\n",
    "    # N.B. No activation function. This is the sum of the output of two convolutions (one 3x3, the other 1x1).\n",
    "    return t + t_downsampled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test that our residual block works gives the correct shape of outputs\n",
    "test_ph1 = tf.placeholder(shape=(None, 28, 28, 1), dtype=tf.float32)\n",
    "test_out1 = res_block(test_ph1, in_filters=1, out_filters=64, stride=2)\n",
    "print('Output shape should be [None, 14, 14, 64]: {}'.format(test_out1.shape))\n",
    "\n",
    "test_ph2 = tf.placeholder(shape=(None, 28, 28, 64), dtype=tf.float32)\n",
    "test_out2 = res_block(test_ph2, in_filters=64, out_filters=64, stride=1)\n",
    "print('Output shape should be [None, 28, 28, 64]: {}'.format(test_out2.shape))\n",
    "\n",
    "# Check that these will actually run\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(test_out1, feed_dict={test_ph1: fake_input_batch})\n",
    "    sess.run(test_out2, feed_dict={test_ph2: np.tile(fake_input_batch, reps=(1, 1, 1, 64))}) # Tile to fake channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_net(input_tensor: tf.Tensor, n_filters: int) -> tf.Tensor:\n",
    "    # Convolution with 3x3 kernels\n",
    "    kernel = tf.Variable(tf.truncated_normal(shape=(3, 3, 1, n_filters), stddev=1e-5, dtype=tf.float32))\n",
    "    biases = tf.Variable(tf.zeros(shape=(1, 1, 1, n_filters), dtype=tf.float32))\n",
    "    conv_output = tf.nn.conv2d(input_tensor, kernel, strides=1, padding='SAME') + biases\n",
    "    # FIXME - two downsampling ResBlocks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
